#!/usr/bin/env python
"""
Handles batch archiving of Nuke scripts using the 'fixarc' core tool.

This script provides a command-line interface to find Nuke scripts (.nk)
within a specified project structure based on project, episode, sequence, or
shot names. It then invokes the 'fixarc' command-line tool for each identified
script to perform the actual archival process.

Key functionalities include:
- Discovering Nuke scripts in predefined 'publish/nuke' directories.
- Filtering scripts by version (latest, all, or top N).
- Allowing specification of project, episode, sequence, or shot scopes.
- Optional submission of archiving tasks to a Deadline render farm.
- Passing through custom options to the underlying 'fixarc' tool.
- Environment variable (`FIXSTORE_DRIVE`) based default for project base paths.

Example Usages:
  # Archive latest version of all shots in project 'MYPROJ'
  fixarc-handler --project MYPROJ --archive-root /mnt/archive

  # Archive latest 3 versions for episode 'EP01' of 'MYPROJ'
  fixarc-handler --project MYPROJ --episode EP01 --max-versions 3 --archive-root /mnt/archive

  # Archive all versions for specific shots, submit to farm, and pass fixarc options
  fixarc-handler --project MYPROJ --shot SH0010 SH0020 \\
    --archive-root /mnt/archive --farm --max-versions 0 \\
    --fixarc-options "--update-script --vendor MyVendor"
"""

import argparse
import sys
import os
import subprocess # For potential calls to fixarc or deadlinecommand
import logging
import shutil # For shutil.which
import glob   # For finding Nuke scripts
import shlex  # For parsing fixarc_options
import tempfile # For Deadline job file creation
from datetime import datetime
import json
import uuid # For generating unique IDs for farm submissions

# --- Path Setup for Imports (BEFORE log object is fully configured) ---
# This setup allows 'from fixarc.deadline...' and for 'fixarc.deadline' to find 'Deadline.api'.

_script_abspath = os.path.realpath(__file__)
_script_bindir = os.path.dirname(_script_abspath)
# _fixarc_package_dir is the directory containing the fixarc package files (deadline.py, constants.py, etc.)
_fixarc_package_dir = os.path.dirname(_script_bindir) 
# _tool_root_path is the parent directory that contains the 'fixarc' package directory
_tool_root_path = os.path.dirname(_fixarc_package_dir)

# 1. Add _tool_root_path for importing 'fixarc.deadline' and other modules within the tool.
#    This makes 'fixarc' importable as a package from _tool_root_path/fixarc/
if _tool_root_path not in sys.path:
    sys.path.insert(0, _tool_root_path)

# 2. Add known Deadline API path directly (no search needed)
_deadline_paths = [
    "Z:/pipe",  # For deployment: Z:/pipe/Deadline
    "C:/Users/robin.d/Documents/dev/pipe"  # For development: C:/Users/robin.d/Documents/dev/pipe/Deadline
]

for deadline_base_path in _deadline_paths:
    if os.path.isdir(os.path.join(deadline_base_path, "Deadline")):
        if deadline_base_path not in sys.path:
            sys.path.insert(0, deadline_base_path)
        break

# Cleanup temporary private variables used for path setup
del _script_abspath, _script_bindir, _fixarc_package_dir, _tool_root_path, _deadline_paths

# Initialize logger global. It will be configured below.
log = None

try:
    # Attempt to use a pre-configured logger from a 'fixfx' package if available.
    # This allows centralized logging if fixarc-handler is part of a larger toolkit.
    from fixfx import log
    using_fixfx_log = True
except ImportError:
    # Fallback to a basic logging configuration if 'fixfx.log' is not available.
    # This ensures that logging is still functional when run standalone.
    logging.basicConfig(
        level=logging.INFO,  # Changed from logging.DEBUG
        format='%(asctime)s [%(levelname)-7s] [%(name)s]: %(message)s'
    )
    log = logging.getLogger("fixarc.handler") # Create/get a logger specific to this script.
    using_fixfx_log = False


def get_command_path(command_name, is_essential=True, relative_fallback_search_dirs=None):
    """Finds the absolute path to a command, optionally checking relative paths.

    Searches for the command in the system's PATH. If not found and
    `relative_fallback_search_dirs` are provided, it checks those directories.
    On Windows, it also attempts to find executables with common extensions
    (e.g., .exe, .bat) if the command_name doesn't include one.

    Args:
        command_name (str): The name of the command to find (e.g., "fixarc", "deadlinecommand").
        is_essential (bool, optional): If True and the command is not found,
            the script will log an error and exit. If False, it logs a warning
            and returns None. Defaults to True.
        relative_fallback_search_dirs (list[str], optional): A list of directory paths
            to search if the command is not found in PATH. Paths are typically
            relative to this script's location. Defaults to None.

    Returns:
        str | None: The absolute, real path to the command if found, otherwise None
        (if `is_essential` is False and command is not found).

    Raises:
        SystemExit: If `is_essential` is True and the command cannot be found.
    """
    cmd_path = shutil.which(command_name)

    if not cmd_path and relative_fallback_search_dirs:
        if not isinstance(relative_fallback_search_dirs, list):
            relative_fallback_search_dirs = [relative_fallback_search_dirs]
        for fallback_dir in relative_fallback_search_dirs:
            # On Windows, command_name might not have .exe, .bat etc. shutil.which handles this.
            # For manual check, we might need to test for common extensions if just command_name is given.
            # However, if relative_fallback_search_dirs implies a direct file, os.path.isfile is fine.
            potential_path_direct = os.path.join(fallback_dir, command_name)
            if os.path.isfile(potential_path_direct) and os.access(potential_path_direct, os.X_OK):
                cmd_path = os.path.realpath(potential_path_direct)
                log.info(f"Found '{command_name}' via relative path: {cmd_path}")
                break
            # Try with common windows executable extensions if on windows
            if sys.platform == "win32" and not os.path.splitext(command_name)[1]:
                 for ext in os.environ.get("PATHEXT", ".EXE;.BAT;.CMD;.COM").split(os.pathsep):
                    potential_path_ext = os.path.join(fallback_dir, command_name + ext.lower())
                    if os.path.isfile(potential_path_ext) and os.access(potential_path_ext, os.X_OK):
                        cmd_path = os.path.realpath(potential_path_ext)
                        log.info(f"Found '{command_name}' (as {os.path.basename(cmd_path)}) via relative path: {cmd_path}")
                        break
                 if cmd_path: # If found with an extension, break the outer loop
                     break

    if cmd_path:
        cmd_path = os.path.realpath(cmd_path) # Ensure absolute and canonical path
        log.debug(f"Found command '{command_name}' at: {cmd_path}")
        return cmd_path
    else:
        msg = f"Command '{command_name}' not found in PATH or specified fallback locations."
        if is_essential:
            log.error(msg)
            sys.exit(1) # Critical command missing, exit script.
        else:
            log.warning(msg) # Non-critical, allow script to potentially continue.
            return None

def build_search_paths(mode, project_name, names_to_process, base_path):
    """Builds a list of absolute directory paths to search for Nuke scripts.

    The construction of search paths depends on the operating `mode` and the
    provided names (episodes, sequences, or shots). It assumes a standard
    project directory structure:
    `{base_path}/{project_name}/shots/{episode_name}/{sequence_name}/{shot_name}`.

    Args:
        mode (str): The operational mode ("project", "episode", "sequence", "shot").
        project_name (str): The name of the project.
        names_to_process (list[str]): A list of names (episode, sequence, or shot names)
            to process. This is empty if `mode` is "project".
        base_path (str): The absolute base path for all projects (e.g., "/mnt/proj", "W:\\proj").

    Returns:
        tuple[list[str], list[str]]: A tuple containing two lists:
            - search_paths: A list of valid, existing absolute directory paths to search.
            - missing_search_roots: A list of paths that were expected but not found.
    """
    search_paths = []
    missing_search_roots = []
    log.info(f"Determining search paths (Mode: {mode}, Project: {project_name}, Base: {base_path})")

    if mode == "project":
        # For project mode, search the root 'shots' directory of the project.
        search_root = os.path.join(base_path, project_name, "shots")
        if not os.path.isdir(search_root):
            log.error(f"Project shots directory not found: {search_root}")
            missing_search_roots.append(search_root)
        else:
            search_paths.append(search_root)
            log.info(f"Added search path for project '{project_name}': {search_root}")

    elif mode == "episode":
        log.info(f"Targeting episodes for project: {project_name}")
        for episode_name in names_to_process:
            # Assumes episode_name is an identifier like "BOB_101"
            # Structure: {base_path}/{project_name}/shots/{episode_name}/
            search_root = os.path.join(base_path, project_name, "shots", episode_name)
            if not os.path.isdir(search_root):
                log.warning(f"Episode directory not found: {search_root}. Will not search here.")
                missing_search_roots.append(search_root)
            else:
                search_paths.append(search_root)
                log.info(f"Added search path for episode '{episode_name}': {search_root}")

    elif mode == "sequence":
        log.info(f"Targeting sequences for project: {project_name}")
        for seq_name in names_to_process:
            # Expects seq_name like "BOB_101_00X"
            # Tries to infer episode_dir from the first two parts (e.g., "BOB_101")
            parts = seq_name.split('_')
            if len(parts) >= 2:
                 episode_dir_guess = f"{parts[0]}_{parts[1]}"
            elif len(parts) == 1: # Handles cases like sequence 'MAIN' under episode 'MAIN'
                 episode_dir_guess = parts[0]
            else: # Should not happen if names_to_process has items and names are valid
                log.warning(f"Sequence name '{seq_name}' is too short to reliably determine episode path. Skipping.")
                continue
            
            # Structure: {base_path}/{project_name}/shots/{episode_dir_guess}/{seq_name}/
            search_root = os.path.join(base_path, project_name, "shots", episode_dir_guess, seq_name)
            if not os.path.isdir(search_root):
                log.warning(f"Sequence directory not found: {search_root}. Will not search here.")
                missing_search_roots.append(search_root)
            else:
                search_paths.append(search_root)
                log.info(f"Added search path for sequence '{seq_name}': {search_root}")

    elif mode == "shot":
        log.info(f"Targeting shots for project: {project_name}")
        for shot_name in names_to_process:
            # Expects shot_name format like: EP_EPNUM_SEQNUM_SHOTNUM_TASK (e.g., BOB_101_010_005_CMP)
            # or at least EP_EPNUM_SEQNUM_SHOTNUM
            parts = shot_name.split('_')
            if len(parts) < 3: # Minimum for EP_EPNUM_SEQNUM for sequence_dir
                log.warning(f"Shot name '{shot_name}' does not seem to match expected format (e.g., EP_EPNUM_SEQNUM_SHOTNUM_TASK). Cannot reliably determine path. Skipping.")
                continue
            
            episode_dir = f"{parts[0]}_{parts[1]}" # e.g., BOB_101
            sequence_dir = f"{parts[0]}_{parts[1]}_{parts[2]}" # e.g., BOB_101_010
            # Structure: {base_path}/{project_name}/shots/{episode_dir}/{sequence_dir}/{shot_name}/
            search_root = os.path.join(base_path, project_name, "shots", episode_dir, sequence_dir, shot_name)
            if not os.path.isdir(search_root):
                log.warning(f"Shot directory not found: {search_root}. Will not search here.")
                missing_search_roots.append(search_root)
            else:
                search_paths.append(search_root)
                log.info(f"Added search path for shot '{shot_name}': {search_root}")
    
    return search_paths, missing_search_roots

def find_and_filter_nuke_scripts(search_paths, max_versions):
    """Finds Nuke scripts, sorts them by name (naively for version), and filters.

    This function walks through the `search_paths` looking for a
    `publish/nuke` subdirectory. Within these directories, it lists all `.nk`
    files, sorts them lexicographically (which often corresponds to version sorting
    if filenames are well-behaved, e.g., `script_v001.nk`, `script_v002.nk`),
    and then filters them based on the `max_versions` argument.

    Args:
        search_paths (list[str]): A list of absolute directory paths to search.
            Typically generated by `build_search_paths`.
        max_versions (int): The number of latest versions to select.
            - If `<= 0`, all found versions are selected.
            - If `1`, only the lexicographically last version is selected.
            - If `> 1`, the lexicographically last `N` versions are selected.

    Returns:
        list[str]: A list of absolute paths to the selected Nuke script files.
                   Returns an empty list if no scripts are found or if `search_paths` is empty.
    
    Note:
        The version sorting is basic (lexicographical). For more robust natural
        sorting of versions (e.g., 'v2' vs 'v10'), a library like 'natsort'
        or more complex regex-based version extraction would be needed. This
        implementation assumes simple, consistent naming.
    """
    all_found_scripts = []
    if not search_paths:
        log.warning("No search paths provided to find_and_filter_nuke_scripts.")
        return []

    log.info(f"Searching for Nuke scripts (*.nk) in 'publish/nuke' subdirectories and filtering by version (max: {max_versions})...")

    for search_path_root in search_paths:
        # os.walk explores the directory tree starting from search_path_root.
        for dirpath, dirnames, filenames in os.walk(search_path_root):
            # Normalize the path for consistent comparison (e.g., handles mixed slashes).
            norm_dirpath = os.path.normpath(dirpath)
            # We are specifically looking for Nuke scripts in a 'publish/nuke' subdirectory.
            # This is a common convention in VFX pipelines.
            if norm_dirpath.endswith(os.path.join("publish", "nuke")):
                nuke_publish_dir = dirpath # This is the '.../publish/nuke/' directory.
                log.debug(f"Checking Nuke publish directory: {nuke_publish_dir}")
                
                # List all .nk files in this directory.
                # sorted() here provides lexicographical sorting.
                nk_files_in_dir = sorted(
                    [os.path.join(nuke_publish_dir, f) for f in os.listdir(nuke_publish_dir) if f.endswith(".nk") and os.path.isfile(os.path.join(nuke_publish_dir, f))]
                )
                
                if not nk_files_in_dir:
                    log.debug(f"  No .nk files found in {nuke_publish_dir}")
                    continue

                log.debug(f"  Found {len(nk_files_in_dir)} .nk files in {nuke_publish_dir}: {[os.path.basename(f) for f in nk_files_in_dir]}")
                scripts_to_add = []
                if max_versions <= 0: # Archive ALL versions
                    log.info(f"  Selecting ALL {len(nk_files_in_dir)} versions from {os.path.basename(nuke_publish_dir)} (max-versions <= 0).")
                    scripts_to_add.extend(nk_files_in_dir)
                elif max_versions == 1: # Archive LATEST version only
                    log.info(f"  Selecting LATEST version from {os.path.basename(nuke_publish_dir)} (max-versions = 1).")
                    if nk_files_in_dir: # Should always be true if we got here
                        scripts_to_add.append(nk_files_in_dir[-1]) # Get the last element (highest version by sort)
                else: # Archive the latest N versions (max_versions > 1)
                    count = len(nk_files_in_dir)
                    num_to_take = min(max_versions, count) # Take at most 'max_versions' or all if fewer exist.
                    log.info(f"  Selecting LATEST {num_to_take} of {count} versions from {os.path.basename(nuke_publish_dir)} (max-versions = {max_versions}).")
                    scripts_to_add.extend(nk_files_in_dir[-num_to_take:]) # Get the last N elements
                
                all_found_scripts.extend(scripts_to_add)
                if scripts_to_add:
                    log.info(f"  Added {len(scripts_to_add)} script(s) from {os.path.basename(nuke_publish_dir)} to the final list.")
    
    if not all_found_scripts:
        log.warning("No Nuke scripts found matching the criteria in 'publish/nuke' directories within the search paths.")
    else:
        log.info(f"Total Nuke scripts selected for archival: {len(all_found_scripts)}")
        for script_path in all_found_scripts:
            log.debug(f"  - {script_path}") # Log each selected script at debug level
            
    return all_found_scripts

def create_parser():
    """Creates and configures the argparse.ArgumentParser for the script.

    Defines all command-line arguments, their types, help messages, and default values.
    A mutually exclusive group allows specifying a scope (episode, sequence, shot)
    within the project. If no scope is given, it defaults to the entire project.

    Returns:
        argparse.ArgumentParser: The configured argument parser.
    """
    parser = argparse.ArgumentParser(
        description="Handles archiving Nuke scripts for projects, sequences, or shots using 'fixarc'.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter # Shows default values in --help
    )

    # --- Project Context (Now a general required argument) ---
    parser.add_argument(
        "--project", type=str, dest="project_name_arg", metavar="PROJECT_NAME", required=True,
        help="The name of the project. This is always required and provides context "
             "for other scope arguments like --episode, --sequence, or --shot, or for processing the whole project."
    )

    # --- Mutually Exclusive Mode Group (Optional: if none given, defaults to whole project) ---
    # User can optionally narrow down the scope to episode, sequence, or shot.
    # If none are chosen, the script will operate on the entire project specified by --project.
    mode_group = parser.add_mutually_exclusive_group(required=False)
    mode_group.add_argument(
        "--episode", nargs='+', metavar="EPISODE_NAME",
        help="Archive published Nuke scripts in the specified episode(s) of the given --project."
    )
    mode_group.add_argument(
        "--sequence", nargs='+', metavar="SEQUENCE_NAME",
        help="Archive published Nuke scripts in the specified sequence(s) of the given --project."
    )
    mode_group.add_argument(
        "--shot", nargs='+', metavar="SHOT_NAME",
        help="Archive published Nuke scripts in the specified shot(s) of the given --project."
    )

    # --- Required Arguments ---
    parser.add_argument(
        "--archive-root", type=str, required=True,
        help="Root directory path for the archive output structure (e.g., /mnt/archive/MYPROJ_archive)."
    )

    # --- Optional Arguments ---
    parser.add_argument(
        "--base-path", type=str,
        help="Override the default base path for projects (e.g., /mnt/studio/projects, Z:/proj). "
             "If not set, defaults to $FIXSTORE_DRIVE/proj."
    )
    parser.add_argument(
        "--max-versions", type=int, default=1, metavar="N",
        help="Number of latest published script versions to archive per shot context: "
             "N <= 0: ALL versions; N == 1 (default): LATEST version only; N > 1: latest N versions."
    )
    parser.add_argument(
        "--client-config", type=str, metavar="PATH/TO/config.json",
        help="Path to a JSON configuration file for client-specific mapping rules (passed directly to 'fixarc')."
    )
    parser.add_argument(
        "--farm", action="store_true",
        help="Submit each 'fixarc' process as a separate Deadline render farm job."
    )
    parser.add_argument(
        "--fixarc-options", type=str, default="",
        help="A quote-enclosed string of *other* options to be passed directly to each 'fixarc' call "
             "(e.g., \"--update-script --bake-gizmos --frame-range 1001-1050\")."
    )
    parser.add_argument(
        "-v", "--verbose", action="count", default=0,
        help="Increase logging verbosity. -v for INFO (default for this script if not using fixfx.log), "
             "-vv for DEBUG. If using fixfx.log, this script respects its level but can be made more verbose."
    )

    # --- Internal Arguments (for multi-stage farm processing) ---
    # These are not meant for direct user invocation.
    internal_group = parser.add_argument_group('Internal Farm Processing (DO NOT USE DIRECTLY)')
    internal_group.add_argument(
        "--_run-discovery-on-farm", action="store_true",
        help=argparse.SUPPRESS # Hide from help
    )
    internal_group.add_argument(
        "--_output-script-list", type=str, metavar="PATH",
        help=argparse.SUPPRESS
    )
    internal_group.add_argument(
        "--_run-archival-submission-on-farm", action="store_true",
        help=argparse.SUPPRESS
    )
    internal_group.add_argument(
        "--_input-script-list", type=str, metavar="PATH",
        help=argparse.SUPPRESS
    )
    internal_group.add_argument(
        "--_farm-submission-uuid", type=str, metavar="UUID", # To correlate logs/files if needed
        help=argparse.SUPPRESS
    )
    # To pass original scope for Batch Name construction in the archival submission phase
    internal_group.add_argument(
        "--_original-project-name", type=str, help=argparse.SUPPRESS
    )
    internal_group.add_argument(
        "--_original-mode", type=str, help=argparse.SUPPRESS # project, episode, sequence, shot
    )
    internal_group.add_argument(
        "--_original-names-to-process", nargs='*', help=argparse.SUPPRESS
    )
    internal_group.add_argument(
        "--_original-archive-root", type=str, help=argparse.SUPPRESS
    )
    internal_group.add_argument(
        "--_original-client-config", type=str, help=argparse.SUPPRESS
    )
    internal_group.add_argument(
        "--_original-fixarc-options", type=str, help=argparse.SUPPRESS
    )
    # We also need the original verbosity for the farm jobs
    internal_group.add_argument(
        "--_original-verbose", type=int, help=argparse.SUPPRESS
    )

    return parser

def _ensure_shared_dir_exists(shared_file_path: str):
    """Ensures the directory for a shared file exists."""
    dir_name = os.path.dirname(shared_file_path)
    if dir_name: # Only if there is a directory part
        try:
            os.makedirs(dir_name, exist_ok=True)
            log.debug(f"Ensured shared directory exists: {dir_name}")
        except OSError as e:
            log.error(f"Failed to create shared directory {dir_name}: {e}")
            raise # Re-raise to halt if we can't create essential paths

def main():
    """Main execution function for the fixarc-handler script.

    Parses command-line arguments, sets up logging, determines the operating mode
    and scripts to process, then either executes 'fixarc' locally or submits
    jobs to a Deadline farm using a multi-stage approach.
    """
    # --- Argument Parsing and Logging Setup ---
    parser = create_parser()
    args = parser.parse_args()

    # Configure logging level based on verbosity flags.
    # If using fixfx.log, its level is the base, but this script can increase its own verbosity.
    if args.verbose == 0:
        log.setLevel(logging.INFO)
    elif args.verbose == 1:
        log.setLevel(logging.INFO)
    elif args.verbose >= 2:
        log.setLevel(logging.DEBUG)

    # Log messages related to Deadline module import status, now that log is configured.
    submit_deadline_job = None
    try:
        from fixarc.deadline import submit_deadline_job
        log.info("Successfully loaded Deadline submission via fixarc.deadline module.")
    except ImportError as e:
        log.error(f"Failed to import submit_deadline_job from fixarc.deadline: {e}")
        log.error("Ensure Deadline Python API is accessible and 'fixarc.deadline' module is correct.")
        log.error("Farm submission will not be available.")

    # Check if we are using the fixfx logger or the internal fallback.
    if using_fixfx_log:
        log.info("fixarc-handler: Using logger from 'fixfx' package.")
    else:
        log.info("fixarc-handler: Using internal basic logger ('fixarc.handler').")
        if log.level > logging.WARNING:
            log.warning("fixarc-handler: (Reminder) Could not import 'log' from 'fixfx'. Basic logging in use.")

    log.debug(f"fixarc-handler: Effective logging level set to {logging.getLevelName(log.level)}.")
    log.debug(f"Parsed arguments: {args}")

    # --- Determine Operating Mode and Target Names (needed early for batch name) ---
    project_name = args.project_name_arg
    mode = "project"
    names_to_process = []
    if args.episode: mode = "episode"; names_to_process = args.episode
    elif args.sequence: mode = "sequence"; names_to_process = args.sequence
    elif args.shot: mode = "shot"; names_to_process = args.shot

    # --- Handle Different Execution Modes ---

    if args._run_discovery_on_farm:
        # FARM WORKER: Run script discovery and write to JSON file
        log.info("[FARM DISCOVERY MODE] Starting Nuke script discovery.")
        if not args._output_script_list:
            log.error("[FARM DISCOVERY MODE] --_output-script-list not specified. Cannot proceed.")
            sys.exit(1)

        base_path_to_use = args.base_path # Should be passed through by the initial submitter
        if not base_path_to_use:
            fixstore_drive = os.environ.get("FIXSTORE_DRIVE")
            if not fixstore_drive:
                log.error("[FARM DISCOVERY MODE] Cannot determine base path. Set FIXSTORE_DRIVE or pass --base-path.")
                sys.exit(1)
            base_path_to_use = os.path.join(fixstore_drive, "proj")
        base_path_to_use = os.path.normpath(base_path_to_use)
        log.info(f"[FARM DISCOVERY MODE] Using base project path: {base_path_to_use}")

        search_paths, _ = build_search_paths(mode, project_name, names_to_process, base_path_to_use)
        found_scripts = find_and_filter_nuke_scripts(search_paths, args.max_versions)
        
        try:
            _ensure_shared_dir_exists(args._output_script_list)
            with open(args._output_script_list, 'w') as f_out:
                json.dump(found_scripts, f_out, indent=2)
            log.info(f"[FARM DISCOVERY MODE] Successfully wrote {len(found_scripts)} script paths to {args._output_script_list}")
            sys.exit(0)
        except Exception as e_json:
            log.error(f"[FARM DISCOVERY MODE] Failed to write script list to {args._output_script_list}: {e_json}")
            sys.exit(1)

    elif args._run_archival_submission_on_farm:
        # FARM WORKER: Read script list from JSON and submit individual fixarc jobs
        log.info("[FARM ARCHIVAL SUBMISSION MODE] Starting individual 'fixarc' job submissions.")
        if not args._input_script_list:
            log.error("[FARM ARCHIVAL SUBMISSION MODE] --_input-script-list not specified. Cannot proceed.")
            sys.exit(1)
        
        if not submit_deadline_job: # Crucial check
             log.error("[FARM ARCHIVAL SUBMISSION MODE] Deadline module (submit_deadline_job) not available. Cannot submit archive jobs.")
             sys.exit(1)

        try:
            with open(args._input_script_list, 'r') as f_in:
                found_scripts_for_submission = json.load(f_in)
            log.info(f"[FARM ARCHIVAL SUBMISSION MODE] Read {len(found_scripts_for_submission)} scripts from {args._input_script_list}")
        except Exception as e_json_read:
            log.error(f"[FARM ARCHIVAL SUBMISSION MODE] Failed to read script list from {args._input_script_list}: {e_json_read}")
            sys.exit(1)

        if not found_scripts_for_submission:
            log.warning("[FARM ARCHIVAL SUBMISSION MODE] No scripts found in the list. Nothing to submit.")
            sys.exit(0)

        # --- Construct BatchName using original parameters passed through --_original-* args ---
        original_proj_name = args._original_project_name or project_name # Fallback to current if not passed
        original_mode = args._original_mode or mode
        original_names = args._original_names_to_process or names_to_process
        original_archive_root = args._original_archive_root or args.archive_root
        original_client_config = args._original_client_config or args.client_config
        original_fixarc_options_str = args._original_fixarc_options or args.fixarc_options
        original_verbosity = args._original_verbose if args._original_verbose is not None else args.verbose

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        batch_name_parts = [f"fixarc - {timestamp} - {original_proj_name}"]
        if original_mode == "episode" and original_names:
            batch_name_parts.append(original_names[0])
        elif original_mode == "sequence" and original_names:
            seq_name_for_batch = original_names[0]
            seq_parts = seq_name_for_batch.split('_')
            if len(seq_parts) >= 2: batch_name_parts.append(f"{seq_parts[0]}_{seq_parts[1]}")
            batch_name_parts.append(seq_name_for_batch)
        batch_name_str = " - ".join(batch_name_parts)
        batch_name_sanitized = "".join(c if c.isalnum() or c in ('_', '-', '.', ':', ' ') else '_' for c in batch_name_str).strip()
        log.info(f"[FARM ARCHIVAL SUBMISSION MODE] Deadline Batch Name: {batch_name_sanitized}")

        fixarc_python_script_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), "fixarc")
        if not os.path.isfile(fixarc_python_script_path):
            log.error(f"[FARM ARCHIVAL SUBMISSION MODE] Core 'fixarc' Python script not found: {fixarc_python_script_path}")
            sys.exit(1)

        success_submission_count = 0
        failed_submission_count = 0
        current_user_farm = os.environ.get('USER', os.environ.get('USERNAME', 'unknown_user'))

        parsed_original_fixarc_options = shlex.split(original_fixarc_options_str) if original_fixarc_options_str else []

        for i, script_path_farm in enumerate(found_scripts_for_submission):
            script_norm_farm = os.path.normpath(script_path_farm)
            script_basename_farm = os.path.basename(script_norm_farm)
            log.info(f"--- Preparing Deadline job for script [{i+1}/{len(found_scripts_for_submission)}]: '{script_basename_farm}' ---")

            # Derive Job Name (shot name)
            shot_metadata_farm = {}
            try:
                from fixarc.utils import get_metadata_from_path
                shot_metadata_farm = get_metadata_from_path(script_norm_farm)
            except Exception as meta_e_farm:
                log.warning(f"Could not get metadata for '{script_basename_farm}': {meta_e_farm}")
            job_shot_name_farm = shot_metadata_farm.get("shot") or shot_metadata_farm.get("shot_name") or original_proj_name
            if job_shot_name_farm == original_proj_name: # Fallback parsing
                name_parts_farm = script_basename_farm.split('_')
                if len(name_parts_farm) >= 4: job_shot_name_farm = "_".join(name_parts_farm[:4])
            
            # Arguments for the 'fixarc' core script
            current_fixarc_cmd_args_farm = [
                fixarc_python_script_path,
                script_norm_farm,
                "--archive-root", original_archive_root # Use original archive root
            ]
            if original_verbosity >= 2: current_fixarc_cmd_args_farm.append("-vv")
            elif original_verbosity == 1: current_fixarc_cmd_args_farm.append("-v")
            if original_client_config:
                if not os.path.isfile(original_client_config):
                    log.error(f"Client config '{original_client_config}' not found. Skipping: {script_basename_farm}")
                    failed_submission_count += 1; continue
                current_fixarc_cmd_args_farm.extend(["--client-config", original_client_config])
            if parsed_original_fixarc_options: # Already parsed list
                current_fixarc_cmd_args_farm.extend(parsed_original_fixarc_options)

            fixarc_args_str_farm = ' '.join(f'{shlex.quote(arg)}' for arg in current_fixarc_cmd_args_farm)

            deadline_job_info_farm = {
                "Plugin": "CommandLine",
                "Name": str(job_shot_name_farm),
                "BatchName": batch_name_sanitized,
                "Comment": f"Archive {script_norm_farm} via fixarc for project {original_proj_name}",
                "UserName": current_user_farm,
                "Frames": "0",
                "InitialStatus": "Active",
                "MachineLimit": 1,
                "Executable": sys.executable,
                "Arguments": fixarc_args_str_farm
            }
            try:
                job_id_farm = submit_deadline_job(job_info=deadline_job_info_farm)
                if job_id_farm: log.info(f"  Submitted job for {script_basename_farm}. ID: {job_id_farm}"); success_submission_count += 1
                else: log.error(f"  Failed to submit job for {script_basename_farm}."); failed_submission_count += 1
            except Exception as e_submit_farm:
                log.error(f"  Error submitting job for {script_basename_farm}: {e_submit_farm}", exc_info=True); failed_submission_count += 1
            log.info("------------------------------")
        
        log.info(f"[FARM ARCHIVAL SUBMISSION MODE] Finished. Submitted: {success_submission_count}, Failed: {failed_submission_count}")
        sys.exit(0 if failed_submission_count == 0 else 1)

    # --- Standard Local Execution or Initial Farm Submission --- 
    current_script_dir = os.path.dirname(os.path.realpath(__file__))
    fixarc_cmd_path = get_command_path("fixarc", is_essential=True, relative_fallback_search_dirs=[current_script_dir])
    log.info(f"Using 'fixarc' command for local execution (if not farm) or as reference: {fixarc_cmd_path}")

    # Determine Base Path for Project Structure (needed for initial discovery job or local run)
    base_path_to_use = args.base_path
    if not base_path_to_use:
        fixstore_drive = os.environ.get("FIXSTORE_DRIVE")
        if not fixstore_drive:
            log.error("Cannot determine default base path. Set FIXSTORE_DRIVE or use --base-path.")
            sys.exit(1)
        base_path_to_use = os.path.join(fixstore_drive, "proj")
    base_path_to_use = os.path.normpath(base_path_to_use)
    log.info(f"Using base project path: {base_path_to_use}")

    if args.farm:
        # LOCAL: This is the initial invocation by the user with --farm
        log.info("[FARM MODE - LOCAL INVOCATION] Submitting multi-stage farm processing pipeline.")
        if not submit_deadline_job:
            log.error("Farm submission requested but Deadline module not available. Cannot initiate farm pipeline.")
            sys.exit(1)

        farm_submission_uuid = str(uuid.uuid4())
        # TODO: Define a shared path for the script list. This needs to be accessible by farm workers.
        # Example: args.archive_root / ".fixarc_farm_temp" / farm_submission_uuid / "discovered_scripts.json"
        # For now, using a path relative to archive_root (ensure archive_root is accessible from farm)
        shared_temp_dir_name = ".fixarc_farm_temp"
        shared_script_list_filename = f"scripts_{farm_submission_uuid}.json"
        # Construct path based on archive_root which should be a shared location
        # Ensure archive_root itself is valid and accessible before forming this path.
        if not os.path.isdir(args.archive_root):
            try:
                os.makedirs(args.archive_root, exist_ok=True)
                log.info(f"Created archive root directory: {args.archive_root}")
            except OSError as e_mkdir:
                log.error(f"Archive root '{args.archive_root}' does not exist and could not be created: {e_mkdir}")
                log.error("Cannot determine shared path for farm processing. Ensure archive_root is a valid, accessible shared location.")
                sys.exit(1)
        
        shared_script_list_path = os.path.join(args.archive_root, shared_temp_dir_name, shared_script_list_filename)
        _ensure_shared_dir_exists(shared_script_list_path)
        log.info(f"Shared script list for farm will be at: {shared_script_list_path}")

        # Job 1: Discovery on Farm
        discovery_job_name = f"FixArc_Discovery_{project_name}_{farm_submission_uuid[:8]}"
        discovery_args_list = [
            sys.executable,
            os.path.realpath(__file__), # This script
            "--project", project_name,
            "--base-path", base_path_to_use,
            "--max-versions", str(args.max_versions),
            "--_run-discovery-on-farm",
            "--_output-script-list", shared_script_list_path,
            "--_farm-submission-uuid", farm_submission_uuid
        ]
        if args.episode: discovery_args_list.extend(["--episode"] + args.episode)
        elif args.sequence: discovery_args_list.extend(["--sequence"] + args.sequence)
        elif args.shot: discovery_args_list.extend(["--shot"] + args.shot)
        if args.verbose >= 2: discovery_args_list.append("-vv")
        elif args.verbose == 1: discovery_args_list.append("-v")
        
        discovery_job_info = {
            "Plugin": "CommandLine",
            "Name": discovery_job_name,
            "Comment": f"Discover Nuke scripts for {project_name}",
            "UserName": current_user,
            "Frames": "0",
            "InitialStatus": "Active",
            "Executable": discovery_args_list[0], # python.exe
            "Arguments": ' '.join(f'{shlex.quote(arg)}' for arg in discovery_args_list[1:])
        }
        log.info(f"Submitting Discovery Job to Deadline: {discovery_job_name}")
        discovery_job_id = submit_deadline_job(job_info=discovery_job_info)

        if not discovery_job_id:
            log.error("Failed to submit Discovery Job to Deadline. Halting farm submission.")
            sys.exit(1)
        log.info(f"Discovery Job submitted. ID: {discovery_job_id}")

        # Job 2: Archival Submission on Farm (depends on Job 1)
        archival_submit_job_name = f"FixArc_SubmitArchives_{project_name}_{farm_submission_uuid[:8]}"
        archival_submit_args_list = [
            sys.executable,
            os.path.realpath(__file__), # This script
            "--_run-archival-submission-on-farm",
            "--_input-script-list", shared_script_list_path,
            "--_farm-submission-uuid", farm_submission_uuid,
            # Pass original args for batch name and individual job construction
            "--_original-project-name", project_name,
            "--_original-mode", mode,
            "--_original-archive-root", args.archive_root # Crucial for archive path
        ]
        if names_to_process: archival_submit_args_list.extend(["--_original-names-to-process"] + names_to_process)
        if args.client_config: archival_submit_args_list.extend(["--_original-client-config", args.client_config])
        if args.fixarc_options: archival_submit_args_list.extend(["--_original-fixarc-options", args.fixarc_options])
        archival_submit_args_list.extend(["--_original-verbose", str(args.verbose)]) # Pass verbosity
        if args.verbose >= 2: archival_submit_args_list.append("-vv") # Set verbosity for this job itself too
        elif args.verbose == 1: archival_submit_args_list.append("-v")

        archival_submit_job_info = {
            "Plugin": "CommandLine",
            "Name": archival_submit_job_name,
            "Comment": f"Submit individual archive jobs for {project_name} based on discovered scripts",
            "UserName": current_user,
            "Frames": "0",
            "JobDependencies": discovery_job_id, # Depends on discovery job
            "InitialStatus": "Active", # Will be Suspended if dep is not complete, then Active
            "Executable": archival_submit_args_list[0],
            "Arguments": ' '.join(f'{shlex.quote(arg)}' for arg in archival_submit_args_list[1:])
        }
        log.info(f"Submitting Archival Submission Job to Deadline: {archival_submit_job_name}")
        archival_submit_job_id = submit_deadline_job(job_info=archival_submit_job_info)

        if not archival_submit_job_id:
            log.error("Failed to submit Archival Submission Job to Deadline.")
            # Note: Discovery job is already queued. Manual cleanup might be needed in Deadline.
            sys.exit(1)
        
        log.info(f"Archival Submission Job submitted. ID: {archival_submit_job_id}")
        log.info("Farm processing pipeline successfully submitted. Monitor Deadline for progress.")
        sys.exit(0) # Local handler exits after successfully queuing the farm pipeline

    # --- LOCAL EXECUTION (No --farm, or --farm handled above) ---
    # This part runs if not --farm, or if it's a farm worker in a later stage (but those exit earlier)
    log.info(f"Operating Mode: {mode}")
    log.info(f"Project Name: {project_name}")
    if names_to_process: log.info(f"Names to process: {names_to_process}")
    log.info(f"Archive Root: {args.archive_root}")

    # --- Find Nuke Scripts (Only for local execution now) ---
    # For farm, discovery happens in a separate farm job.
    search_paths, missing_search_roots = build_search_paths(mode, project_name, names_to_process, base_path_to_use)

    if not search_paths:
        log.error("No valid search paths could be determined to find Nuke scripts based on inputs.")
        if missing_search_roots:
            log.error("The following expected directories were missing or inaccessible:")
            for missing_path in missing_search_roots: log.error(f"  - {missing_path}")
        sys.exit(1)

    found_scripts = find_and_filter_nuke_scripts(search_paths, args.max_versions)

    if not found_scripts:
        log.error("Process halting: No Nuke scripts were found to process with the given criteria.")
        if missing_search_roots: # Remind user if some paths were unsearchable
            log.warning("Note: The following expected directories were missing and could not be searched:")
            for missing_path in missing_search_roots: log.warning(f"  - {missing_path}")
        sys.exit(1) # Exit if no scripts are found.

    if missing_search_roots:
        log.warning("Warning: Some expected source directories were missing during the Nuke script search:")
        for missing_path in missing_search_roots: log.warning(f"  - {missing_path}")
        try:
            user_response = input("Do you want to continue archiving the scripts that were found? (y/N) ").strip().lower()
            if user_response != 'y': log.info("User aborted operation."); sys.exit(3)
        except EOFError: log.warning("Non-interactive. Aborting due to missing dirs."); sys.exit(3)

    parsed_fixarc_options = []
    if args.fixarc_options:
        try: parsed_fixarc_options = shlex.split(args.fixarc_options)
        except Exception as e_shlex: log.error(f"Error parsing --fixarc-options: {e_shlex}")
    
    success_count = 0
    fail_count = 0
    failed_script_details = []

    # --- LOCAL Script Processing Loop (Only runs if NOT --farm initial call) ---
    # The farm logic was handled above and exits. This loop is for local execution only.
    log.info(f"[LOCAL EXECUTION] Starting archival process for {len(found_scripts)} Nuke script(s)...")
        for i, script_path in enumerate(found_scripts):
            script_norm = os.path.normpath(script_path)
            script_basename = os.path.basename(script_norm)
        log.info(f"--- Processing script [{i+1}/{len(found_scripts)}]: '{script_basename}' ---")
            
            base_cmd_args = [fixarc_cmd_path, script_norm, "--archive-root", args.archive_root]
        if args.verbose >= 2: base_cmd_args.append("-vv")
        elif args.verbose == 1: base_cmd_args.append("-v")
            if args.client_config:
            if not os.path.isfile(args.client_config): log.error(f"Client config '{args.client_config}' not found. Skipping: {script_basename}"); fail_count +=1; continue
                base_cmd_args.extend(["--client-config", args.client_config])
        if parsed_fixarc_options: base_cmd_args.extend(parsed_fixarc_options)

                log.info(f"Executing 'fixarc' locally for {script_basename}...") 
                try:
                    process = subprocess.run(base_cmd_args, check=True, text=True, encoding='utf-8', capture_output=True)
                    log.info(f"Successfully archived: {script_basename}")
            if process.stdout.strip(): log.debug(f"  fixarc stdout:\n{process.stdout.strip()}")
                    success_count += 1
                except subprocess.CalledProcessError as e:
                    log.error(f"'fixarc' command FAILED for: {script_basename} (Exit code: {e.returncode})")
            failed_script_details.append({"name": script_basename, "returncode": e.returncode, "stderr": e.stderr.strip() if e.stderr else "No stderr."})
            if e.stdout.strip(): log.warning(f"  fixarc stdout on error:\n{e.stdout.strip()}")
            if e.stderr.strip(): log.warning(f"  fixarc stderr on error:\n{e.stderr.strip()}")
                    fail_count += 1
                except FileNotFoundError: 
            log.error(f"Critical error: 'fixarc' command not found at {fixarc_cmd_path}. Halting for {script_basename}.")
            failed_script_details.append({"name": script_basename, "returncode": -1, "stderr": f"'fixarc' not found at {fixarc_cmd_path}."})
                    fail_count += 1 
        log.info("------------------------------")

    # --- Final Summary (for local execution) ---
    log.info("--- Archiving Process Summary (Local Execution) ---")
        log.info(f"Local 'fixarc' execution complete.")
        log.info(f"Scripts successfully archived: {success_count}")
        log.info(f"Scripts failed to archive: {fail_count}")
    # (Error details logging as before)
        if failed_script_details:
            log.error("--- Details of Failed Scripts ---")
            for failure in failed_script_details:
                log.error(f"  Script: {failure['name']}")
                error_lines = failure['stderr'].splitlines()
            concise_error = "\n".join(error_lines[-5:])
            if not concise_error and failure['stderr']: concise_error = failure['stderr'][:300] + ('...' if len(failure['stderr']) > 300 else '')
                log.error(f"    Exit Code: {failure['returncode']}")
                log.error(f"    Error Snippet: {concise_error if concise_error else 'No specific error message captured in stderr.'}")
            log.debug(f"    Full stderr for {failure['name']}:\n{failure['stderr']}")

    if missing_search_roots: # Remind user at the end as well
        log.warning("Reminder: Some expected source directories were missing during the search process:")
        for missing_path in missing_search_roots: log.warning(f"  - {missing_path}")

    if fail_count > 0: log.info("fixarc-handler finished with errors."); sys.exit(1)
    else: log.info("fixarc-handler finished successfully."); sys.exit(0)

if __name__ == "__main__":
    # This ensures main() is called only when the script is executed directly.
    main() 