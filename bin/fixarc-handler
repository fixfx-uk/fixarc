#!/usr/bin/env python
"""
Handles batch archiving of Nuke scripts using the 'fixarc' core tool.

This script provides a command-line interface to find Nuke scripts (.nk)
within a specified project structure based on project, episode, sequence, or
shot names. It then invokes the 'fixarc' command-line tool for each identified
script to perform the actual archival process.

Key functionalities include:
- Discovering Nuke scripts in predefined 'publish/nuke' directories.
- Filtering scripts by version (latest, all, or top N).
- Allowing specification of project, episode, sequence, or shot scopes.
- Optional submission of archiving tasks to a Deadline render farm.
- Passing through custom options to the underlying 'fixarc' tool.
- Environment variable (`FIXSTORE_DRIVE`) based default for project base paths.

Example Usages:
  # Archive latest version of all shots in project 'MYPROJ'
  fixarc-handler --project MYPROJ --archive-root /mnt/archive

  # Archive latest 3 versions for episode 'EP01' of 'MYPROJ'
  fixarc-handler --project MYPROJ --episode EP01 --max-versions 3 --archive-root /mnt/archive

  # Archive all versions for specific shots, submit to farm, and pass fixarc options
  fixarc-handler --project MYPROJ --shot SH0010 SH0020 \\
    --archive-root /mnt/archive --farm --max-versions 0 \\
    --fixarc-options "--update-script --vendor MyVendor"
"""

import argparse
import sys
import os
import subprocess # For potential calls to fixarc or deadlinecommand
import logging
import shutil # For shutil.which
import glob   # For finding Nuke scripts
import shlex  # For parsing fixarc_options
import tempfile # For Deadline job file creation
from datetime import datetime

# --- Path Setup for Imports (BEFORE log object is fully configured) ---
# This setup allows 'from fixarc.deadline...' and for 'fixarc.deadline' to find 'Deadline.api'.

_script_abspath = os.path.realpath(__file__)
_script_bindir = os.path.dirname(_script_abspath)
# _fixarc_package_dir is the directory containing the fixarc package files (deadline.py, constants.py, etc.)
_fixarc_package_dir = os.path.dirname(_script_bindir) 
# _tool_root_path is the parent directory that contains the 'fixarc' package directory
_tool_root_path = os.path.dirname(_fixarc_package_dir)

# 1. Add _tool_root_path for importing 'fixarc.deadline' and other modules within the tool.
#    This makes 'fixarc' importable as a package from _tool_root_path/fixarc/
if _tool_root_path not in sys.path:
    sys.path.insert(0, _tool_root_path)

# 2. Add known Deadline API path directly (no search needed)
_deadline_paths = [
    "Z:/pipe",  # For deployment: Z:/pipe/Deadline
    "C:/Users/robin.d/Documents/dev/pipe"  # For development: C:/Users/robin.d/Documents/dev/pipe/Deadline
]

for deadline_base_path in _deadline_paths:
    if os.path.isdir(os.path.join(deadline_base_path, "Deadline")):
        if deadline_base_path not in sys.path:
            sys.path.insert(0, deadline_base_path)
        break

# Cleanup temporary private variables used for path setup
del _script_abspath, _script_bindir, _fixarc_package_dir, _tool_root_path, _deadline_paths

# Initialize logger global. It will be configured below.
log = None

try:
    # Attempt to use a pre-configured logger from a 'fixfx' package if available.
    # This allows centralized logging if fixarc-handler is part of a larger toolkit.
    from fixfx import log
    using_fixfx_log = True
except ImportError:
    # Fallback to a basic logging configuration if 'fixfx.log' is not available.
    # This ensures that logging is still functional when run standalone.
    logging.basicConfig(
        level=logging.INFO,  # Changed from logging.DEBUG
        format='%(asctime)s [%(levelname)-7s] [%(name)s]: %(message)s'
    )
    log = logging.getLogger("fixarc.handler") # Create/get a logger specific to this script.
    using_fixfx_log = False


def get_command_path(command_name, is_essential=True, relative_fallback_search_dirs=None):
    """Finds the absolute path to a command, optionally checking relative paths.

    Searches for the command in the system's PATH. If not found and
    `relative_fallback_search_dirs` are provided, it checks those directories.
    On Windows, it also attempts to find executables with common extensions
    (e.g., .exe, .bat) if the command_name doesn't include one.

    Args:
        command_name (str): The name of the command to find (e.g., "fixarc", "deadlinecommand").
        is_essential (bool, optional): If True and the command is not found,
            the script will log an error and exit. If False, it logs a warning
            and returns None. Defaults to True.
        relative_fallback_search_dirs (list[str], optional): A list of directory paths
            to search if the command is not found in PATH. Paths are typically
            relative to this script's location. Defaults to None.

    Returns:
        str | None: The absolute, real path to the command if found, otherwise None
        (if `is_essential` is False and command is not found).

    Raises:
        SystemExit: If `is_essential` is True and the command cannot be found.
    """
    cmd_path = shutil.which(command_name)

    if not cmd_path and relative_fallback_search_dirs:
        if not isinstance(relative_fallback_search_dirs, list):
            relative_fallback_search_dirs = [relative_fallback_search_dirs]
        for fallback_dir in relative_fallback_search_dirs:
            # On Windows, command_name might not have .exe, .bat etc. shutil.which handles this.
            # For manual check, we might need to test for common extensions if just command_name is given.
            # However, if relative_fallback_search_dirs implies a direct file, os.path.isfile is fine.
            potential_path_direct = os.path.join(fallback_dir, command_name)
            if os.path.isfile(potential_path_direct) and os.access(potential_path_direct, os.X_OK):
                cmd_path = os.path.realpath(potential_path_direct)
                log.info(f"Found '{command_name}' via relative path: {cmd_path}")
                break
            # Try with common windows executable extensions if on windows
            if sys.platform == "win32" and not os.path.splitext(command_name)[1]:
                 for ext in os.environ.get("PATHEXT", ".EXE;.BAT;.CMD;.COM").split(os.pathsep):
                    potential_path_ext = os.path.join(fallback_dir, command_name + ext.lower())
                    if os.path.isfile(potential_path_ext) and os.access(potential_path_ext, os.X_OK):
                        cmd_path = os.path.realpath(potential_path_ext)
                        log.info(f"Found '{command_name}' (as {os.path.basename(cmd_path)}) via relative path: {cmd_path}")
                        break
                 if cmd_path: # If found with an extension, break the outer loop
                     break

    if cmd_path:
        cmd_path = os.path.realpath(cmd_path) # Ensure absolute and canonical path
        log.debug(f"Found command '{command_name}' at: {cmd_path}")
        return cmd_path
    else:
        msg = f"Command '{command_name}' not found in PATH or specified fallback locations."
        if is_essential:
            log.error(msg)
            sys.exit(1) # Critical command missing, exit script.
        else:
            log.warning(msg) # Non-critical, allow script to potentially continue.
            return None

def build_search_paths(mode, project_name, names_to_process, base_path):
    """Builds a list of absolute directory paths to search for Nuke scripts.

    The construction of search paths depends on the operating `mode` and the
    provided names (episodes, sequences, or shots). It assumes a standard
    project directory structure:
    `{base_path}/{project_name}/shots/{episode_name}/{sequence_name}/{shot_name}`.

    Args:
        mode (str): The operational mode ("project", "episode", "sequence", "shot").
        project_name (str): The name of the project.
        names_to_process (list[str]): A list of names (episode, sequence, or shot names)
            to process. This is empty if `mode` is "project".
        base_path (str): The absolute base path for all projects (e.g., "/mnt/proj", "W:\\proj").

    Returns:
        tuple[list[str], list[str]]: A tuple containing two lists:
            - search_paths: A list of valid, existing absolute directory paths to search.
            - missing_search_roots: A list of paths that were expected but not found.
    """
    search_paths = []
    missing_search_roots = []
    log.info(f"Determining search paths (Mode: {mode}, Project: {project_name}, Base: {base_path})")

    if mode == "project":
        # For project mode, search the root 'shots' directory of the project.
        search_root = os.path.join(base_path, project_name, "shots")
        if not os.path.isdir(search_root):
            log.error(f"Project shots directory not found: {search_root}")
            missing_search_roots.append(search_root)
        else:
            search_paths.append(search_root)
            log.info(f"Added search path for project '{project_name}': {search_root}")

    elif mode == "episode":
        log.info(f"Targeting episodes for project: {project_name}")
        for episode_name in names_to_process:
            # Assumes episode_name is an identifier like "BOB_101"
            # Structure: {base_path}/{project_name}/shots/{episode_name}/
            search_root = os.path.join(base_path, project_name, "shots", episode_name)
            if not os.path.isdir(search_root):
                log.warning(f"Episode directory not found: {search_root}. Will not search here.")
                missing_search_roots.append(search_root)
            else:
                search_paths.append(search_root)
                log.info(f"Added search path for episode '{episode_name}': {search_root}")

    elif mode == "sequence":
        log.info(f"Targeting sequences for project: {project_name}")
        for seq_name in names_to_process:
            # Expects seq_name like "BOB_101_00X"
            # Tries to infer episode_dir from the first two parts (e.g., "BOB_101")
            parts = seq_name.split('_')
            if len(parts) >= 2:
                 episode_dir_guess = f"{parts[0]}_{parts[1]}"
            elif len(parts) == 1: # Handles cases like sequence 'MAIN' under episode 'MAIN'
                 episode_dir_guess = parts[0]
            else: # Should not happen if names_to_process has items and names are valid
                log.warning(f"Sequence name '{seq_name}' is too short to reliably determine episode path. Skipping.")
                continue
            
            # Structure: {base_path}/{project_name}/shots/{episode_dir_guess}/{seq_name}/
            search_root = os.path.join(base_path, project_name, "shots", episode_dir_guess, seq_name)
            if not os.path.isdir(search_root):
                log.warning(f"Sequence directory not found: {search_root}. Will not search here.")
                missing_search_roots.append(search_root)
            else:
                search_paths.append(search_root)
                log.info(f"Added search path for sequence '{seq_name}': {search_root}")

    elif mode == "shot":
        log.info(f"Targeting shots for project: {project_name}")
        for shot_name in names_to_process:
            # Expects shot_name format like: EP_EPNUM_SEQNUM_SHOTNUM_TASK (e.g., BOB_101_010_005_CMP)
            # or at least EP_EPNUM_SEQNUM_SHOTNUM
            parts = shot_name.split('_')
            if len(parts) < 3: # Minimum for EP_EPNUM_SEQNUM for sequence_dir
                log.warning(f"Shot name '{shot_name}' does not seem to match expected format (e.g., EP_EPNUM_SEQNUM_SHOTNUM_TASK). Cannot reliably determine path. Skipping.")
                continue
            
            episode_dir = f"{parts[0]}_{parts[1]}" # e.g., BOB_101
            sequence_dir = f"{parts[0]}_{parts[1]}_{parts[2]}" # e.g., BOB_101_010
            # Structure: {base_path}/{project_name}/shots/{episode_dir}/{sequence_dir}/{shot_name}/
            search_root = os.path.join(base_path, project_name, "shots", episode_dir, sequence_dir, shot_name)
            if not os.path.isdir(search_root):
                log.warning(f"Shot directory not found: {search_root}. Will not search here.")
                missing_search_roots.append(search_root)
            else:
                search_paths.append(search_root)
                log.info(f"Added search path for shot '{shot_name}': {search_root}")
    
    return search_paths, missing_search_roots

def find_and_filter_nuke_scripts(search_paths, max_versions):
    """Finds Nuke scripts, sorts them by name (naively for version), and filters.

    This function walks through the `search_paths` looking for a
    `publish/nuke` subdirectory. Within these directories, it lists all `.nk`
    files, sorts them lexicographically (which often corresponds to version sorting
    if filenames are well-behaved, e.g., `script_v001.nk`, `script_v002.nk`),
    and then filters them based on the `max_versions` argument.

    Args:
        search_paths (list[str]): A list of absolute directory paths to search.
            Typically generated by `build_search_paths`.
        max_versions (int): The number of latest versions to select.
            - If `<= 0`, all found versions are selected.
            - If `1`, only the lexicographically last version is selected.
            - If `> 1`, the lexicographically last `N` versions are selected.

    Returns:
        list[str]: A list of absolute paths to the selected Nuke script files.
                   Returns an empty list if no scripts are found or if `search_paths` is empty.
    
    Note:
        The version sorting is basic (lexicographical). For more robust natural
        sorting of versions (e.g., 'v2' vs 'v10'), a library like 'natsort'
        or more complex regex-based version extraction would be needed. This
        implementation assumes simple, consistent naming.
    """
    all_found_scripts = []
    if not search_paths:
        log.warning("No search paths provided to find_and_filter_nuke_scripts.")
        return []

    log.info(f"Searching for Nuke scripts (*.nk) in 'publish/nuke' subdirectories and filtering by version (max: {max_versions})...")

    for search_path_root in search_paths:
        # os.walk explores the directory tree starting from search_path_root.
        for dirpath, dirnames, filenames in os.walk(search_path_root):
            # Normalize the path for consistent comparison (e.g., handles mixed slashes).
            norm_dirpath = os.path.normpath(dirpath)
            # We are specifically looking for Nuke scripts in a 'publish/nuke' subdirectory.
            # This is a common convention in VFX pipelines.
            if norm_dirpath.endswith(os.path.join("publish", "nuke")):
                nuke_publish_dir = dirpath # This is the '.../publish/nuke/' directory.
                log.debug(f"Checking Nuke publish directory: {nuke_publish_dir}")
                
                # List all .nk files in this directory.
                # sorted() here provides lexicographical sorting.
                nk_files_in_dir = sorted(
                    [os.path.join(nuke_publish_dir, f) for f in os.listdir(nuke_publish_dir) if f.endswith(".nk") and os.path.isfile(os.path.join(nuke_publish_dir, f))]
                )
                
                if not nk_files_in_dir:
                    log.debug(f"  No .nk files found in {nuke_publish_dir}")
                    continue

                log.debug(f"  Found {len(nk_files_in_dir)} .nk files in {nuke_publish_dir}: {[os.path.basename(f) for f in nk_files_in_dir]}")
                scripts_to_add = []
                if max_versions <= 0: # Archive ALL versions
                    log.info(f"  Selecting ALL {len(nk_files_in_dir)} versions from {os.path.basename(nuke_publish_dir)} (max-versions <= 0).")
                    scripts_to_add.extend(nk_files_in_dir)
                elif max_versions == 1: # Archive LATEST version only
                    log.info(f"  Selecting LATEST version from {os.path.basename(nuke_publish_dir)} (max-versions = 1).")
                    if nk_files_in_dir: # Should always be true if we got here
                        scripts_to_add.append(nk_files_in_dir[-1]) # Get the last element (highest version by sort)
                else: # Archive the latest N versions (max_versions > 1)
                    count = len(nk_files_in_dir)
                    num_to_take = min(max_versions, count) # Take at most 'max_versions' or all if fewer exist.
                    log.info(f"  Selecting LATEST {num_to_take} of {count} versions from {os.path.basename(nuke_publish_dir)} (max-versions = {max_versions}).")
                    scripts_to_add.extend(nk_files_in_dir[-num_to_take:]) # Get the last N elements
                
                all_found_scripts.extend(scripts_to_add)
                if scripts_to_add:
                    log.info(f"  Added {len(scripts_to_add)} script(s) from {os.path.basename(nuke_publish_dir)} to the final list.")
    
    if not all_found_scripts:
        log.warning("No Nuke scripts found matching the criteria in 'publish/nuke' directories within the search paths.")
    else:
        log.info(f"Total Nuke scripts selected for archival: {len(all_found_scripts)}")
        for script_path in all_found_scripts:
            log.debug(f"  - {script_path}") # Log each selected script at debug level
            
    return all_found_scripts

def create_parser():
    """Creates and configures the argparse.ArgumentParser for the script.

    Defines all command-line arguments, their types, help messages, and default values.
    A mutually exclusive group allows specifying a scope (episode, sequence, shot)
    within the project. If no scope is given, it defaults to the entire project.

    Returns:
        argparse.ArgumentParser: The configured argument parser.
    """
    parser = argparse.ArgumentParser(
        description="Handles archiving Nuke scripts for projects, sequences, or shots using 'fixarc'.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter # Shows default values in --help
    )

    # --- Project Context (Now a general required argument) ---
    parser.add_argument(
        "--project", type=str, dest="project_name_arg", metavar="PROJECT_NAME", required=True,
        help="The name of the project. This is always required and provides context "
             "for other scope arguments like --episode, --sequence, or --shot, or for processing the whole project."
    )

    # --- Mutually Exclusive Mode Group (Optional: if none given, defaults to whole project) ---
    # User can optionally narrow down the scope to episode, sequence, or shot.
    # If none are chosen, the script will operate on the entire project specified by --project.
    mode_group = parser.add_mutually_exclusive_group(required=False)
    mode_group.add_argument(
        "--episode", nargs='+', metavar="EPISODE_NAME",
        help="Archive published Nuke scripts in the specified episode(s) of the given --project."
    )
    mode_group.add_argument(
        "--sequence", nargs='+', metavar="SEQUENCE_NAME",
        help="Archive published Nuke scripts in the specified sequence(s) of the given --project."
    )
    mode_group.add_argument(
        "--shot", nargs='+', metavar="SHOT_NAME",
        help="Archive published Nuke scripts in the specified shot(s) of the given --project."
    )

    # --- Required Arguments ---
    parser.add_argument(
        "--archive-root", type=str, required=True,
        help="Root directory path for the archive output structure (e.g., /mnt/archive/MYPROJ_archive)."
    )

    # --- Optional Arguments ---
    parser.add_argument(
        "--base-path", type=str,
        help="Override the default base path for projects (e.g., /mnt/studio/projects, Z:/proj). "
             "If not set, defaults to $FIXSTORE_DRIVE/proj."
    )
    parser.add_argument(
        "--max-versions", type=int, default=1, metavar="N",
        help="Number of latest published script versions to archive per shot context: "
             "N <= 0: ALL versions; N == 1 (default): LATEST version only; N > 1: latest N versions."
    )
    parser.add_argument(
        "--client-config", type=str, metavar="PATH/TO/config.json",
        help="Path to a JSON configuration file for client-specific mapping rules (passed directly to 'fixarc')."
    )
    parser.add_argument(
        "--farm", action="store_true",
        help="Submit each 'fixarc' process as a separate Deadline render farm job."
    )
    parser.add_argument(
        "--fixarc-options", type=str, default="",
        help="A quote-enclosed string of *other* options to be passed directly to each 'fixarc' call "
             "(e.g., \"--update-script --bake-gizmos --frame-range 1001-1050\")."
    )
    parser.add_argument(
        "-v", "--verbose", action="count", default=0,
        help="Increase logging verbosity. -v for INFO (default for this script if not using fixfx.log), "
             "-vv for DEBUG. If using fixfx.log, this script respects its level but can be made more verbose."
    )
    return parser

def main():
    """Main execution function for the fixarc-handler script.

    Parses command-line arguments, sets up logging, determines the operating mode
    and scripts to process, then either executes 'fixarc' locally or submits
    jobs to a Deadline farm.
    """
    # --- Argument Parsing and Logging Setup ---
    parser = create_parser()
    args = parser.parse_args()

    # Configure logging level based on verbosity flags.
    # If using fixfx.log, its level is the base, but this script can increase its own verbosity.
    if args.verbose == 0:
        log.setLevel(logging.INFO)
    elif args.verbose == 1:
        log.setLevel(logging.INFO)
    elif args.verbose >= 2:
        log.setLevel(logging.DEBUG)

    # Log messages related to Deadline module import status, now that log is configured.
    submit_deadline_job = None
    try:
        from fixarc.deadline import submit_deadline_job
        log.info("Successfully loaded Deadline submission via fixarc.deadline module.")
    except ImportError as e:
        log.error(f"Failed to import submit_deadline_job from fixarc.deadline: {e}")
        log.error("Ensure Deadline Python API is accessible and 'fixarc.deadline' module is correct.")
        log.error("Farm submission will not be available.")

    # Check if we are using the fixfx logger or the internal fallback.
    if using_fixfx_log:
        log.info("fixarc-handler: Using logger from 'fixfx' package.")
    else:
        log.info("fixarc-handler: Using internal basic logger ('fixarc.handler').")
        if log.level > logging.WARNING:
            log.warning("fixarc-handler: (Reminder) Could not import 'log' from 'fixfx'. Basic logging in use.")

    log.debug(f"fixarc-handler: Effective logging level set to {logging.getLevelName(log.level)}.")
    log.debug(f"Parsed arguments: {args}")

    # --- Locate Essential Commands ---
    current_script_dir = os.path.dirname(os.path.realpath(__file__))
    fixarc_cmd_path = get_command_path("fixarc", is_essential=True, relative_fallback_search_dirs=[current_script_dir])
    log.info(f"Using 'fixarc' command: {fixarc_cmd_path}")

    if args.farm:
        if not submit_deadline_job:
            log.error("Farm submission requested but Deadline module not available.")
            sys.exit(1)
        else:
            log.info("Farm submission via Deadline Python API will be used.")

    # --- Determine Operating Mode and Target Names ---
    project_name = args.project_name_arg # Get project name from the general --project argument

    mode = "project" # Default mode: process the whole project
    names_to_process = [] # List of specific episodes, sequences, or shots

    if args.episode:
        mode = "episode"
        names_to_process = args.episode
    elif args.sequence:
        mode = "sequence"
        names_to_process = args.sequence
    elif args.shot:
        mode = "shot"
        names_to_process = args.shot
    # If none of the above (episode, sequence, shot) are specified, 
    # the mode remains "project" and names_to_process remains empty,
    # indicating processing for the entire project_name.
    
    log.info(f"Operating Mode: {mode}")
    log.info(f"Project Name: {project_name}")
    if names_to_process:
        log.info(f"Names to process: {names_to_process}")
    log.info(f"Archive Root: {args.archive_root}")

    # --- Determine Base Path for Project Structure ---
    base_path_to_use = args.base_path
    if not base_path_to_use:
        # If --base-path is not provided, attempt to use FIXSTORE_DRIVE environment variable.
        fixstore_drive = os.environ.get("FIXSTORE_DRIVE")
        if not fixstore_drive:
            log.error("Cannot determine default base path. "
                      "Please set the FIXSTORE_DRIVE environment variable (e.g., 'W:' or '/mnt/fixstore') "
                      "or use the --base-path argument.")
            sys.exit(1)
        base_path_to_use = os.path.join(fixstore_drive, "proj") # Standard convention: $FIXSTORE_DRIVE/proj
    
    # Normalize the path (e.g., converts slashes, resolves '..') for consistency.
    base_path_to_use = os.path.normpath(base_path_to_use)
    log.info(f"Using base project path: {base_path_to_use}")

    # --- Find Nuke Scripts ---
    search_paths, missing_search_roots = build_search_paths(mode, project_name, names_to_process, base_path_to_use)

    if not search_paths:
        log.error("No valid search paths could be determined to find Nuke scripts based on inputs.")
        if missing_search_roots:
            log.error("The following expected directories were missing or inaccessible:")
            for missing_path in missing_search_roots:
                log.error(f"  - {missing_path}")
        sys.exit(1)

    found_scripts = find_and_filter_nuke_scripts(search_paths, args.max_versions)

    if not found_scripts:
        log.error("Process halting: No Nuke scripts were found to process with the given criteria.")
        if missing_search_roots: # Remind user if some paths were unsearchable
            log.warning("Note: The following expected directories were missing and could not be searched:")
            for missing_path in missing_search_roots:
                log.warning(f"  - {missing_path}")
        sys.exit(1) # Exit if no scripts are found.

    # If some directories were missing but scripts were still found elsewhere, prompt user to continue.
    if missing_search_roots:
        log.warning("Warning: Some expected source directories were missing during the Nuke script search:")
        for missing_path in missing_search_roots:
            log.warning(f"  - {missing_path}")
        try:
            # Python's input() for user confirmation.
            user_response = input("Do you want to continue archiving the scripts that were found? (y/N) ").strip().lower()
            if user_response != 'y':
                log.info("User aborted operation due to missing directories.")
                sys.exit(3) # Exit code 3 for user abort.
        except EOFError: # Handle non-interactive environments (e.g., automated scripts)
            log.warning("Non-interactive environment detected. Cannot prompt for confirmation about missing directories. "
                        "Aborting as a safety measure.")
            sys.exit(3) # Abort in non-interactive if directories are missing.

    # Parse --fixarc-options string into a list of arguments
    parsed_fixarc_options = []
    if args.fixarc_options:
        try:
            # shlex.split is used for proper parsing of quoted strings within the options.
            parsed_fixarc_options = shlex.split(args.fixarc_options)
            log.debug(f"Parsed --fixarc-options: {parsed_fixarc_options}")
        except Exception as e:
            log.error(f"Error parsing --fixarc-options string: '{args.fixarc_options}'. Error: {e}")
            log.warning("Proceeding without additional fixarc options due to parsing error.")
            # Continue with an empty list if parsing fails.

    # --- Process Found Scripts (Local Execution or Farm Submission) ---
    success_count = 0
    fail_count = 0
    failed_script_details = [] # New list to store details of failed scripts
    try:
        current_user = os.getlogin()
    except OSError: # os.getlogin() can fail in some non-interactive/daemonized environments
        current_user = os.environ.get('USER', os.environ.get('USERNAME', 'unknown_user'))

    total_scripts = len(found_scripts)
    log.info(f"Starting archival process for {total_scripts} Nuke script(s)...")

    if args.farm:
        # --- Farm Submission Logic ---
        if not submit_deadline_job:
            log.error("Farm submission requested but Deadline module (submit_deadline_job) not available.")
            log.error("Cannot proceed with farm submission.")
            sys.exit(1) # Exit if farm submission is impossible

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Construct BatchName
        batch_name_parts = [f"fixarc - {timestamp} - {project_name}"]
        if mode == "episode" and names_to_process:
            batch_name_parts.append(names_to_process[0])
        elif mode == "sequence" and names_to_process:
            # Try to infer episode from sequence for a more complete batch name
            # Example: seq "PROJ_ep01_sc010" -> episode "PROJ_ep01"
            seq_name_for_batch = names_to_process[0]
            seq_parts = seq_name_for_batch.split('_')
            if len(seq_parts) >= 2: # project_episode
                inferred_episode_for_batch = f"{seq_parts[0]}_{seq_parts[1]}"
                batch_name_parts.append(inferred_episode_for_batch)
            batch_name_parts.append(seq_name_for_batch)
        
        batch_name_str = " - ".join(batch_name_parts)
        # Sanitize BatchName for Deadline
        batch_name_sanitized = "".join(c if c.isalnum() or c in ('_', '-', '.', ':', ' ') else '_' for c in batch_name_str).strip()
        log.info(f"Deadline Batch Name: {batch_name_sanitized}")

        # Path to the actual 'fixarc' Python script (not the .BAT wrapper)
        # Assuming 'fixarc' (python script) is in the same directory as 'fixarc-handler'
        fixarc_python_script_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), "fixarc")
        if not os.path.isfile(fixarc_python_script_path):
            log.error(f"Core 'fixarc' Python script not found at expected location: {fixarc_python_script_path}")
            log.error("Cannot proceed with farm submission.")
            sys.exit(1)

        for i, script_path in enumerate(found_scripts):
            script_norm = os.path.normpath(script_path)
            script_basename = os.path.basename(script_norm)
            log.info(f"--- Preparing Deadline job for script [{i+1}/{total_scripts}]: '{script_basename}' ---")

            # Derive shot_name for Deadline Job Name
            # Attempt to get metadata for the specific script to extract shot name
            shot_metadata = {}
            try:
                from fixarc.utils import get_metadata_from_path # Local import for clarity
                shot_metadata = get_metadata_from_path(script_norm)
            except Exception as meta_e:
                log.warning(f"Could not get detailed metadata for script '{script_basename}' to determine shot name: {meta_e}")
            
            job_shot_name = shot_metadata.get("shot") or \
                            shot_metadata.get("shot_name") or \
                            project_name # Fallback to project name if shot cannot be derived

            # Further fallback: try to parse from basename if metadata fails
            if job_shot_name == project_name:
                # Basic parsing: BOB_104_0B5_010_BLU_Comp_v005.nk -> BOB_104_0B5_010_BLU
                name_parts = script_basename.split('_')
                if len(name_parts) >= 4: # Proj_Ep_Seq_Shot
                    job_shot_name = "_".join(name_parts[:4])


            # Construct base command arguments for 'fixarc' (the Python script)
            # These will be passed to 'python.exe <fixarc_python_script_path> ...'
            current_fixarc_cmd_args = [
                fixarc_python_script_path,
                script_norm,
                "--archive-root", args.archive_root
            ]
            if args.verbose >= 2: current_fixarc_cmd_args.append("-vv")
            elif args.verbose == 1: current_fixarc_cmd_args.append("-v")
            if args.client_config:
                if not os.path.isfile(args.client_config):
                    log.error(f"Client config file not found: {args.client_config}. Skipping farm job for: {script_basename}")
                    fail_count += 1
                    continue
                current_fixarc_cmd_args.extend(["--client-config", args.client_config])
            if parsed_fixarc_options:
                current_fixarc_cmd_args.extend(parsed_fixarc_options)
            
            # For Deadline API, arguments should be a string for CommandLine plugin.
            # Arguments start from the script path, not including 'python.exe'
            fixarc_arguments_str = ' '.join(f'{shlex.quote(arg)}' for arg in current_fixarc_cmd_args)

            deadline_job_info = {
                "Plugin": "CommandLine",
                "Name": str(job_shot_name), # Deadline Job Name is the shot
                "BatchName": batch_name_sanitized, # Group jobs by this batch name
                "Comment": f"Archive {script_norm} via fixarc-handler for project {project_name}",
                "UserName": current_user,
                "Frames": "0", # Single task job for this specific script
                "InitialStatus": "Active",
                "MachineLimit": 1, # One machine per script archival
                "Executable": sys.executable, # Full path to python.exe
                "Arguments": fixarc_arguments_str # Arguments for 'fixarc' python script
            }
            
            log.info(f"  Submitting job to Deadline: Name='{job_shot_name}', Batch='{batch_name_sanitized}'")
            log.debug(f"  Job Executable: {sys.executable}")
            log.debug(f"  Job Arguments: {fixarc_arguments_str}")
            
            try:
                job_id = submit_deadline_job(job_info=deadline_job_info)
                if job_id:
                    log.info(f"  Successfully submitted job for {script_basename} to Deadline. Job ID: {job_id}")
                    success_count += 1
                else:
                    log.error(f"  Failed to submit job for {script_basename} to Deadline via Python API.")
                    fail_count += 1
            except Exception as e:
                log.error(f"  An unexpected error occurred during Deadline job submission for {script_basename}: {e}", exc_info=True)
                fail_count += 1
            log.info("------------------------------")

    else:
        # --- Local Execution Logic (remains largely the same) ---
        for i, script_path in enumerate(found_scripts):
            script_norm = os.path.normpath(script_path)
            script_basename = os.path.basename(script_norm)
            log.info(f"--- Processing script [{i+1}/{total_scripts}]: '{script_basename}' ---")

            # Construct the base command for 'fixarc' (this uses fixarc_cmd_path which could be .BAT)
            base_cmd_args = [fixarc_cmd_path, script_norm, "--archive-root", args.archive_root]
            
            if args.verbose >= 2: base_cmd_args.append("-vv")
            elif args.verbose == 1: base_cmd_args.append("-v")
            if args.client_config:
                if not os.path.isfile(args.client_config):
                    log.error(f"Client config file not found: {args.client_config}. Skipping: {script_basename}")
                    fail_count +=1; continue
                base_cmd_args.extend(["--client-config", args.client_config])
            if parsed_fixarc_options: base_cmd_args.extend(parsed_fixarc_options)

            log.info(f"Executing 'fixarc' locally for {script_basename}...")
            try:
                process = subprocess.run(base_cmd_args, check=True, text=True, encoding='utf-8', capture_output=True)
                log.info(f"Successfully archived: {script_basename}")
                if process.stdout.strip(): log.debug(f"  fixarc stdout:\\n{process.stdout.strip()}")
                success_count += 1
            except subprocess.CalledProcessError as e:
                log.error(f"'fixarc' command FAILED for: {script_basename} (Exit code: {e.returncode})")
                failed_script_details.append({"name": script_basename, "returncode": e.returncode, "stderr": e.stderr.strip() if e.stderr else "No stderr."})
                if e.stdout.strip(): log.warning(f"  fixarc stdout on error:\\n{e.stdout.strip()}")
                if e.stderr.strip(): log.warning(f"  fixarc stderr on error:\\n{e.stderr.strip()}")
                fail_count += 1
            except FileNotFoundError: 
                log.error(f"Critical error: 'fixarc' command not found at {fixarc_cmd_path}. Halting for {script_basename}.")
                failed_script_details.append({"name": script_basename, "returncode": -1, "stderr": f"'fixarc' not found at {fixarc_cmd_path}."})
                fail_count += 1 
            log.info("------------------------------")

    # --- Final Summary ---
    log.info("--- Archiving Process Summary ---")
    if args.farm:
        log.info(f"Deadline job submission process complete.")
        log.info(f"Jobs successfully submitted to Deadline: {success_count}")
        log.info(f"Jobs failed to submit to Deadline: {fail_count}")
        log.info("Note: Check Deadline Monitor for the actual completion status and detailed logs of submitted jobs.")
    else:
        log.info(f"Local 'fixarc' execution complete.")
        log.info(f"Scripts successfully archived: {success_count}")
        log.info(f"Scripts failed to archive: {fail_count}")
        if failed_script_details:
            log.error("--- Details of Failed Scripts ---")
            for failure in failed_script_details:
                log.error(f"  Script: {failure['name']}")
                # Attempt to get a concise error message, e.g., last few lines of stderr
                error_lines = failure['stderr'].splitlines()
                concise_error = "\n".join(error_lines[-5:]) # Last 5 lines, or fewer if less
                if not concise_error and failure['stderr']: # if last 5 lines are empty but there is stderr
                    concise_error = failure['stderr'][:300] + ('...' if len(failure['stderr']) > 300 else '')


                log.error(f"    Exit Code: {failure['returncode']}")
                log.error(f"    Error Snippet: {concise_error if concise_error else 'No specific error message captured in stderr.'}")
                log.debug(f"    Full stderr for {failure['name']}:\n{failure['stderr']}") # Log full for debug

    if missing_search_roots: # Remind user at the end as well if some directories were not found
        log.warning("Reminder: Some expected source directories were missing during the search process:")
        for missing_path in missing_search_roots:
            log.warning(f"  - {missing_path}")

    if fail_count > 0:
        log.info("fixarc-handler finished with errors.")
        sys.exit(1) # Exit with error code 1 if any failures occurred.
    else:
        log.info("fixarc-handler finished successfully.")
        sys.exit(0) # Exit with success code 0.

if __name__ == "__main__":
    # This ensures main() is called only when the script is executed directly.
    main() 